<!DOCTYPE html>
<html lang="en">
<head>


  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Protecting Privacy with Synthetic Training Data using Dual GANs</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" type="text/css">

  <!-- Font -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono" rel="stylesheet">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Tejpal Virdi" href="/feed.xml" />
  <!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Protecting Privacy with Synthetic Training Data using Dual GANs | tvirdi.github.io</title>
<meta property="og:title" content="Protecting Privacy with Synthetic Training Data using Dual GANs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We explore a stacked GAN architecture to produce synthetic training data that avoids privacy concerns and allows for sufficient training of deep, data-hungry networks." />
<meta property="og:description" content="We explore a stacked GAN architecture to produce synthetic training data that avoids privacy concerns and allows for sufficient training of deep, data-hungry networks." />
<link rel="canonical" href="http://localhost:4000/2017-11-25/dcgan/" />
<meta property="og:url" content="http://localhost:4000/2017-11-25/dcgan/" />
<meta property="og:site_name" content="tvirdi.github.io" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-11-25T00:00:00-08:00" />
<script type="application/ld+json">
{"name":null,"description":"We explore a stacked GAN architecture to produce synthetic training data that avoids privacy concerns and allows for sufficient training of deep, data-hungry networks.","author":null,"@type":"BlogPosting","url":"http://localhost:4000/2017-11-25/dcgan/","image":null,"publisher":null,"headline":"Protecting Privacy with Synthetic Training Data using Dual GANs","dateModified":"2017-11-25T00:00:00-08:00","datePublished":"2017-11-25T00:00:00-08:00","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017-11-25/dcgan/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->



  <!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>




</head>

<body>
  <div class="content-container">
    <header>
  <div class="header-small">
    <a href="http://localhost:4000">Tejpal Virdi</a>
  </div>
</header>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



<div class="post">
  <div class="post-title">Protecting Privacy with Synthetic Training Data using Dual GANs</div>
  <span class="post-date">
    <time>25 Nov 2017</time>
  </span>
  <div class="post-tag">
    <ul>
      
    </ul>
  </div>

  <p><strong>November 25th 2017</strong> - Tejpal Virdi</p>

<h3 id="introduction">Introduction</h3>
<p>The growth of Deep Learning in the last few years has been reliant on an immense amount of computational power and extensive datasets. For example, the annual ImageNet competition decreased image recognition error rates from 28.2% to 6.7% by providing millions of labeled images. However, these datasets are not available for many domains. This blog post analyzes the use of Generative Adversarial Networks (GANs) for developing reliable synthetic training data.</p>

<p>A special feature of GANs is its ability to generate images that no one has seen before. As we saw two posts ago, the generator is not trained on the training images but rather on trying to minimize the loss function of the discriminator. Since the generator never sees the images that the discriminator is trained on, it is not likely for it to produce images that are copies of it (given the training data is varied enough) but instead images of similar structure (learning from the distribution).</p>

<p>Since the produced images have never been seen before, it preserves a valuable characteristic: privacy. Many datasets are not publicly available due to privacy concerns, including: medicine, surveillance, driving, etc; however, these datasets could be reproduced with a GAN. This post looks particularly at generating images, for medical and satellite imaging domains, that are free from privacy concerns.</p>

<p>We also explore a dual GAN architecture, in regards of enhancing the output quality. Stacking GANs has shown to produce images that are of higher quality than a single GAN. Zhang et al. showed this by producing a low-quality image from text-to-image synthesis and then employing a conditional GAN to produce a high-quality image given the low-quality image. For example, we could have a situation where the first GAN produces a segmentation while the second GAN produces a photorealistic satellite image given the segmentation.</p>

<center>
<img id="hello" src="/images/2.jpg" /> 
<img id="hello" src="/images/1.jpg" />
</center>
<style>
    #hello {
        display: inline;
        width: 256px;
        height: 256px;
    }
</style>

<h3 id="applicable-domains">Applicable Domains</h3>
<p>Medical Data is fraught with privacy concerns, meaning that there are various barriers from distributing patient data aside from educational purposes. However, this in turn has hindered the advancement of computer-aided medical diagnosis since deep learning methods are not supported without extensive datasets. Synthetic data, on the other hand, solves this problem by providing sufficient amounts of training data.</p>

<p>Aerial/satellite images are especially difficult to obtain since it is expensive to fly a drone or device to take quality pictures for miles. This limits the publicity of the data since people are not likely to distribute it for free. In addition, there has been controversy on aerial images over residential areas that may obtrude upon privacy.</p>

<p>Another domain that is limited by a lack of public data is security. Surveillance cameras, for example, can be heavily improved with the use of computer vision techniques. Criminals can be easily detected through super-resolution and facial recognition, and computers can easily go through thousands of hours of footage while still being accurate. However, these datasets are not readily available for public research and contribution.</p>

<p>Even when the data is obtained, segmenting it is a tedious and unproductive process for humans. However, these images are extremely useful for creating topographical maps, road planning, disaster mitigation, and much more. Without sufficient data, neural networks are unable to help in these tasks.</p>

<h3 id="methods">Methods</h3>
<p>The first step of the pipeline is to generate the segmentation mask. We employ a DCGAN, as described in our image generation blog post. Although better models exist (DRAGAN, BEGAN, WGAN), we used a DCGAN architecture as we were the most comfortable with it. Itâ€™s nice for image generation since its depth allows for a hierarchical learning of representations. The depth also results in increased stability and higher quality images. However, the millions of parameters will dramatically increase the computational time.</p>

<p><img src="/images/dcganarch.jpg" alt="DCGAN" class="center-image" height="259px" width="631px" /></p>

<p>Regarding the specifics, DCGAN differs from a vanilla GAN in the following ways: replacement of pooling layers with strided convolutions, use of batch normalization in both the generator and discriminator, removal of fully-connected layers (network depth compromises input dimensionality), heavy use of ReLU in the generator, and heavy use of Leaky ReLU in the discriminator. 
We then use the generated mask to condition the mapping from the segmentation to a photorealistic satellite image. The conditional GAN follows the same training process as the normal GAN except it takes in an additional parameter that represents the condition (in our case, the segmentation mask). Here is what it looks like:</p>

<p><img src="/images/cgan.jpg" alt="CGAN" class="center-image" height="184px" width="525px" /></p>

<p>As we saw in the GAN post, the generator and discriminator compete in the minimax game. Here is what it looks like with the additional parameter y:</p>

<p><img src="/images/loss.png" alt="Loss" class="center-image" height="46px" width="585px" /></p>

<p>Finally, here is what our final architecture looks like:</p>

<p><img src="/images/lathe.png" alt="Loss" class="center-image" height="375px" width="720px" /></p>

<h3 id="results">Results</h3>

<p>Here are some results from our experimentation with retina data:</p>

<p><img src="/images/bro.png" alt="Loss" class="center-image" height="322px" width="434px" /></p>

<h2 id="dcgan-code">DCGAN Code</h2>

<h5 id="full-implementation-httpsgithubcomtejpalvdeep-convolutional-gan">Full Implementation: <a href="https://github.com/tejpalv/deep-convolutional-gan">https://github.com/tejpalv/deep-convolutional-gan</a></h5>

<h3 id="imports">Imports</h3>
<script src="https://gist.github.com/tejpalv/2dac81ed74d0086028cb621747bc7d11.js"></script>

<h3 id="hyperparameters-and-dataset">Hyperparameters and Dataset</h3>
<script src="https://gist.github.com/tejpalv/aa7e55a8f0bca1a30f6392533cdaf0ee.js"></script>

<h3 id="discriminator">Discriminator</h3>
<script src="https://gist.github.com/tejpalv/64f5dcb783c0eea35f329cc9f930b2fd.js"></script>

<h3 id="generator">Generator</h3>
<script src="https://gist.github.com/tejpalv/9102a11fef07880598909dcf1ad8c458.js"></script>

<h3 id="init-loss-and-optimizer">Init, Loss, and Optimizer</h3>
<script src="https://gist.github.com/tejpalv/020e4066c76884370e828d98563f1399.js"></script>

<h3 id="training">Training</h3>
<script src="https://gist.github.com/tejpalv/97bc9dfa494379391dfb8ea5b8651360.js"></script>

<h3 id="testing">Testing</h3>
<script src="https://gist.github.com/tejpalv/5aa99847808ac88ddf81b3c8d0dc1e43.js"></script>



  <!-- Disqus -->
  
  <div class="post-disqus">
      <section id="disqus_thread"></section>
      <script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//Tejpal.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  </div>
  

</div>


    <!-- Documents about icons are here: http://fontawesome.io/icons/ -->
<div class="footer">
  <hr />
  <div class="footer-link">
    
	
	
	
	

    
    <a href="https://twitter.com/tejpalv1"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    

    
    <a href="https://github.com/tejpalv"><i class="fa fa-github" aria-hidden="true"></i></a>
    
	
	
	
	

    
	
	
	
	
	
	
	
	

    

    

    
    <a href="mailto:tejpalv8@gmail.com"><i class="fa fa-envelope" aria-hidden="true"></i></a>
    

  </div>
  Â© 2017 Tejpal Virdi. All rights reserved.
</div>

  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

</body>
</html>

